# @package _global_

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .

# Directory for project output files
project_dir: "./output"

# Directory for evaluation output files (inside project_dir)
evaluation_dir: "evaluation"

# Directory for dataset (inside project_dir)
dataset_dir: "dataset"

# Name of the environment to use
environment: "commonroad" # Either "commonroad" or "image_cartpole"

# Random seed for reproducibility
seed: 123

# Automatically select the device (CPU/GPU)
device: "auto"

# Set to false to disable debug output
debug_mode: false

# Whether to log outputs to terminal
verbose: false

# Dataset generation options
dataset:
  # Number of episodes to collect for the dataset
  num_episodes: 100
  # Number of processes for dataset generation
  num_workers: 1
  # Number of episodes per batch
  storage_batch_size: 1024 
  # Number of timesteps for observation
  t_obs: 5
  # Number of timesteps for prediction
  t_pred: 25
  # Number of frames to skip between each recorded observation frame
  obs_skip_frames: 0
  # Number of frames to skip between each recorded prediction frame
  pred_skip_frames: 4
  # Whether to use polar transform for observations
  use_polar_transform: false
  # Whether to preprocess an existing dataset
  preprocess_existing: false
  # Whether to preprocess online (i.e. during training)
  preprocess_online: false
  # Number of worker processes for preprocessing (0 for single-process)
  preprocess_workers: 4
  # Whether to collect with zero, constant, constant_stochastic or full_stochastic actions during the prediction phase
  collect_mode: zero # {zero, constant, constant_stochastic, full_stochastic}

wandb:
  # Enable Weights & Biases logging
  enabled: true
  # Project name for Weights & Biases
  project: PredictiveStateRepresentations-AD
  # Offline mode
  offline: false
  # Optional name for the run (added as postfix after wandb random name)
  run: null

representation:
  # Type of model to use for encoding
  model_type: "PredictiveModelV9M3" # {AutoEncoderModelV0, AutoEncoderModelV1, PredictiveModelV8, PredictiveModelV9, PredictiveModelV9M1, PredictiveModelV9M3, VQVAEPredictiveModel, CartPolePredictiveModel}
  # Path to the model
  model_path: "../models/pretrained/predictive_model_v9m3.pth"

models:
  VQVAEPredictiveModel:
    pretrained_model_path: "../models/pretrained/autoencoder_model_v0.pth"
  PredictiveModelV9:
    pretrained_model_path: "../models/pretrained/autoencoder_model_v0.pth"
  AutoEncoderModelV0:
    kl_weight: 0.001
  PredictiveModelV9M1:
    encoder_learning_rate: 5e-6
    decoder_learning_rate: 2e-5
  PredictiveModelV9M3:
    encoder_learning_rate: 5e-6
    decoder_learning_rate: 2e-5
    survival_loss_weight: 0.1
    detached_srl_learning_rate: 1e-4
  PredictiveModelV9M2:
    pretrained_model_path: "../models/pretrained/autoencoder_model_v0m1.pth"
    decoder_learning_rate: 2e-5
    vib_weight: 0.0001  # Weight for the Variational Information Bottleneck KL loss
    vae_weight: 0.00001  # Weight for the variational decoding KL loss
    condition_on_future_actions: false

# Eval configuration
evaluation:
  # Number of episodes to evaluate
  num_episodes: 100
  # Minimum episode length for evaluation (mitigate unfortunate respawning and obs. buffer not filled)
  min_episode_length: 100

# Recording configuration
recording:
  # Number of episodes to record
  num_episodes_to_keep: 10

# Training configuration
training:
  # Type of model to use for training
  model_type: "PredictiveModelV9M3" # AutoEncoderModelV0, AutoEncoderModelV0M1, AutoEncoderModelV1, PredictiveModelV8, PredictiveModelV9, PredictiveModelV9M1, PredictiveModelV9M2, PredictiveModelV9M3 VQVAEPredictiveModel
  # Set this to the path of a checkpoint to resume training
  warmstart_model: null # "../models/pretrained/predictive_model_v9m1.pth"
  # Whether to continue from the last scheduler state
  warmstart_load_scheduler_state: false
  # Latent representation size
  hidden_dim: 64
  # Number of gradient updates in total
  total_training_steps: 10000000
  # Early stopping configuration
  early_stopping:
    patience: 10  # Number of validation checks without improvement before stopping
    min_delta: 0.000  # Minimum change in monitored value to qualify as an improvement
  # Number of batches to use per epoch (set to null to use all batches)
  batches_per_epoch: 1
  # Select subset of training data (set to null to use all data)
  subset_size: null
  # Batch size for training
  batch_size: 1
  # Minibatch size
  minibatch_size: 8
  # Number of training iterations per batch
  iterations_per_batch: 1 # don't change this!
  # Whether to compute and print a validation error at each minibatch (slow)
  track_val_loss: false
  # Factor to downsample input images using cv2
  downsample_factor: 1
  # Maximum gradient norm for gradient clipping
  max_grad_norm: 2.0
  # Set to true to enable automatic mixed precision
  use_amp: true 
  # Validation set split size (if float, it is the ratio of the dataset, if int, it is the number of samples)
  val_size: 8
  # How often to validate
  validation_interval: 100
  # Whether to use pinned host memory for faster data copies
  pin_memory: true
  # Number of processes for fetching data in dataloader
  num_workers: 0
  # Prefetch factor for dataloader. This is the number of batches to load in advance. Higher values can speed up training.
  prefetch_factor: null
  # Whether to plot predictions during training
  create_plots: true
  # Whether to log training metrics to stdout
  stdout_logging: true
  # Interval for saving model checkpoints
  save_interval: 100
  # Whether to overwrite existing model checkpoints
  overwrite_checkpoints: true
  # Loss function to use for training
  loss:
    mse_weight: 1.0
    l1_weight: 0.0
    diversity_weight: 0.0
    latent_l1_weight: 0.005
    latent_l2_weight: 0.005
    temporal_decay: 0.9
    perceptual_weight: 0.0
    num_scales: 3
    use_sample_weights: false
    r_weight: 1.0
    g_weight: 1.0
    b_weight: 1.0

  # Optimizer options
  optimizer:
    type: "AdamW"
    beta1: 0.9
    beta2: 0.999
    learning_rate: 3e-4
    weight_decay: 1e-5
    momentum: 0.9
    alpha: 0.99

  # Scheduler configuration
  scheduler:
    type: "LinearWarmupCosineAnnealingLR"  # Options: "StepLR", "ExponentialLR", "CosineAnnealingLR", "ReduceLROnPlateau", "NoScheduler" LinearWarmupCosineAnnealingLR
    T_max: 100  # Period of cosine annealing in epochs
    eta_min: 1e-5  # Minimum learning rate
    # Other scheduler options (uncomment if needed):
    # step_size: 30  # Only used for StepLR
    # gamma: 0.1  # Used for StepLR and ExponentialLR
    # factor: 0.5  # Only used for ReduceLROnPlateau
    # patience: 10  # Only used for ReduceLROnPlateau
    # threshold: 1e-4  # Only used for ReduceLROnPlateau

# Reinforcement Learning Training options
rl_training:
  # Warmstart model for training
  warmstart_model: null # "./rl/models/final_model.zip", "latest" # Set to "latest" to use the latest model
  # Path to save trained models
  save_path: "./models"
  # Path to save training logs
  log_path: "./logs"
  # Frequency of evaluation during training
  eval_freq: 100000
  # Number of episodes for evaluation
  n_eval_episodes: 20
  # Frequency of video recording (in steps)
  video_freq: 100000  
  # Length of each video (in steps)
  video_length: 5000 
  # Folder to save videos (relative to project_dir)
  video_folder: "./videos"  
  # Number of parallel environments for training
  num_envs: 16
  # Total number of timesteps for training
  total_timesteps: 10000000
  # Learning rate for the optimizer
  learning_rate: 1e-4
  # Number of steps to collect samples for each update
  n_steps: 1024
  # Target value for the KL divergence
  target_kl: 0.01
  # Batch size for each update
  batch_size: 256
  # Uses state-dependent std instead of parameter-only std
  full_std: true
  # Uses numerically stable exponential for action std
  use_expln: true
  # Ensures actions stay within [-1,1] bounds
  squash_output: false # // AssertionError: squash_output=True is only available when using gSDE (use_sde=True)
  # Whether to normalize the advantages
  normalize_advantage: true
  # Number of epochs to train the model
  n_epochs: 10
  # Discount factor for future rewards
  gamma: 0.99
  # Lambda parameter for Generalized Advantage Estimation
  gae_lambda: 0.95
  # Clipping range for the surrogate objective
  clip_range: 0.2
  # Clip range for the value function
  clip_range_vf: 0.2
  # Initial value for the log std of the policy
  log_std_init: -1.0
  # Coefficient for the entropy loss
  ent_coef: 0.01
  # Coefficient for the value function loss
  vf_coef: 0.5
  # Maximum norm for gradient clipping
  max_grad_norm: 0.5
  # Network architecture for the policy and value function
  net_arch:
    pi: [256, 256]
    vf: [256, 256]
    
  # Enable online state representation learning
  detached_srl: false

  # End-to-end training options
  end_to_end_srl: false  # Set to true to enable end-to-end training

  # Whether to warmstart the model
  load_pretrained_representation: false  # Whether to load pretrained representation model

  # Whether to use raw observations instead of learned representations
  use_raw_observations: false  # Set to true to use raw observations
  
  # CNN policy configuration when using raw observations
  cnn_policy:
    features_dim: 512
    hidden_dims: [256, 128]

# Viewer options
viewer:
  # Range of view in the simulation
  view_range: 65.0
  # Size of the viewer window
  window_size: 64

# Environment-specific options
commonroad: 
  scenario_dir: "scenarios"

  # Number of episodes to collect per scenario
  num_respawns_per_scenario: 1

  # Whether to activate commonroad-geometric's 'async_resets'. 
  async_resets: true
  async_reset_delay: 0.05

  # Whether to collect dataset from existing trajectories in the scenarios
  collect_from_trajectories: false

  # Simulation options
  simulation:
    # Steps for lanelet graph conversion (if any)
    lanelet_graph_conversion_steps: null
    # Use linear projection for lanelets
    linear_lanelet_projection: true
    # Whether to sort lanelet assignments
    sort_lanelet_assignments: false

  # Maximum timestep before respawning
  timeout: 3000

  # Whether to enable PID control (more high-level control with enhanced stability)
  pid_control: false

  # Control space options
  control_space:
    # Minimum acceleration
    lower_bound_acceleration: -6.0
    # Maximum acceleration
    upper_bound_acceleration: 6.5
    # Minimum velocity
    lower_bound_velocity: 0.001
    # Minimum steering angle
    lower_bound_steering: -0.15
    # Maximum steering angle
    upper_bound_steering: 0.15
    # Minimum velocity for steering
    min_velocity_steering: 1.0

  # Respawner options
  respawner:
    # Randomize initial arclength
    random_init_arclength: true
    # Randomize goal arclength
    random_goal_arclength: true
    # Randomize start timestep
    random_start_timestep: true
    # Spawn only at intersections
    only_intersections: false
    # Min and max route length
    route_length: [10, 15]
    # Initial speed distribution
    init_speed: "uniform_random"
    # Minimum initial arclength
    min_init_arclength: 50.0
    # Range for random speed
    random_speed_range: [0.0, 50.0]
    # Initial steering angle distribution
    init_steering_angle: "normal_random"
    # Range for random steering angle
    random_steering_angle_range: [-0.06, 0.06]
    # Params for normal distribution for steering angle
    normal_steering_angle_params: [0.0, 0.015]
    # Noise in initial orientation
    init_orientation_noise: 0.35
    # Noise in initial position
    init_position_noise: 3.0
    # Minimum distance to goal (if any)
    min_goal_distance: 100.0
    # Minimum L2 distance to goal (if any)
    min_goal_distance_l2: 400.0
    # Maximum L2 distance to goal (if any)
    max_goal_distance_l2: null
    # Maximum distance to goal (if any)
    max_goal_distance: null
    # Minimum remaining distance (if any)
    min_remaining_distance: null
    # Maximum outer attempts for respawning
    max_attempts_outer: 50
    # Minimum distance between vehicles
    min_vehicle_distance: 0.0
    # Minimum vehicle speed (if any)
    min_vehicle_speed: null
    # Minimum number of vehicles on route (if any)
    min_vehicles_route: null
    # Maximum inner attempts for respawning
    max_attempts_inner: 5

  # Traffic extraction options
  traffic_extraction:
    # Type of edge drawer to use
    edge_drawer: "NoEdgeDrawer"
    # List of postprocessors to apply
    postprocessors: []
    # Consider only ego-centric incoming edges
    only_ego_inc_edges: false
    # Assign vehicles to multiple lanelets
    assign_multiple_lanelets: true
    # Radius of ego-centric map
    ego_map_radius: 50.0
    # Include lanelet vertices in extraction
    include_lanelet_vertices: false

  # Traffic generation options
  spawn_rate: 1.0

  # Rendering options
  vehicle_expansion_factor: 1.4

image_cartpole:
  max_episode_steps: 500

cartpole:
  max_episode_steps: 500
  render: false